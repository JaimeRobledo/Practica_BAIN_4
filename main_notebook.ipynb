{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1807f23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaime Robledo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import openai\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45eb610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       opinion     label\n",
      "0          Es un gran servicio  positiva\n",
      "1                   Es regular   neutral\n",
      "2          Es un producto útil  positiva\n",
      "3                 Es un fraude  negativa\n",
      "4               Me gusta mucho  positiva\n",
      "5               Es un desastre  negativa\n",
      "6           Es un mal servicio  negativa\n",
      "7        Es un producto inútil  negativa\n",
      "8           No lo recomendaría  negativa\n",
      "9       Me encantó el producto  positiva\n",
      "10                 No me gusta  negativa\n",
      "11               Es fantástico  positiva\n",
      "12                  Me encanta  positiva\n",
      "13         Es un buen producto  positiva\n",
      "14                Es muy bueno  positiva\n",
      "15          Es un mal servicio  negativa\n",
      "16    Es una pérdida de dinero  negativa\n",
      "17         No es nada especial   neutral\n",
      "18       Es un producto normal   neutral\n",
      "19                     Te odio  negativa\n",
      "20         Es un buen servicio  positiva\n",
      "21         Es un gran producto  positiva\n",
      "22      Es un producto decente   neutral\n",
      "23  Es un producto excepcional  positiva\n",
      "24                  Es un robo  negativa\n",
      "25                 Es horrible  negativa\n",
      "26                Es aceptable   neutral\n",
      "27          Es un mal producto  negativa\n",
      "28            Es impresionante  positiva\n",
      "29                Es increíble  positiva\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('INPUT/emociones.csv')\n",
    "df = df[['opinion', 'label']]\n",
    "df = df.dropna()\n",
    "df = df.sample(30, random_state=42).reset_index(drop=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e2123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = \"\"\"Clasifica el sentimiento del siguiente texto como positivo, negativo o neutral:\n",
    "\n",
    "\"{}\"\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = \"\"\"Clasifica el sentimiento del siguiente texto como positivo, negativo o neutral.\n",
    "Ejemplo 1: \\\"Me encantó la película\\\" → positivo\n",
    "Ejemplo 2: \\\"No me gustó para nada\\\" → negativo\n",
    "Ejemplo 3: \\\"Está bien, sin más\\\" → neutral\n",
    "Texto: \"{}\"\n",
    "Respuesta:\"\"\"\n",
    "\n",
    "cot_prompt = \"\"\"Analiza el siguiente texto y razona si es positivo, negativo o neutral.\n",
    "Texto: \"{}\"\n",
    "Primero, explica por qué. Luego, indica si es positivo, negativo o neutral.\"\"\"\n",
    "\n",
    "prompts = {\n",
    "    \"zero-shot\": zero_shot_prompt,\n",
    "    \"few-shot\": few_shot_prompt,\n",
    "    \"chain-of-thought\": cot_prompt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1be4fd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m opinion \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopinion\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 15\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopinion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositivo\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pred:\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36mpredict_openai\u001b[1;34m(opinion, prompt_template)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_openai\u001b[39m(opinion, prompt_template):\n\u001b[0;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(opinion)\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\Jaime Robledo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_openai(opinion, prompt_template):\n",
    "    prompt = prompt_template.format(opinion)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip().lower()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for method, prompt_template in prompts.items():\n",
    "    predictions = []\n",
    "    for opinion in df['opinion']:\n",
    "        pred = predict_openai(opinion,prompt_template)\n",
    "        pred = pred.lower()\n",
    "        if \"positivo\" in pred:\n",
    "            predictions.append(\"positiva\")\n",
    "        elif \"negativo\" in pred:\n",
    "            predictions.append(\"negativa\")\n",
    "        elif \"neutral\" in pred:\n",
    "            predictions.append(\"neutral\")\n",
    "        else:\n",
    "            predictions.append(\"desconocido\")  # Fallback\n",
    "    results[method] = predictions\n",
    "\n",
    "for method, preds in results.items():\n",
    "    print(f\"\\n=== {method.upper()} ===\")\n",
    "    print(classification_report(df['label'], preds, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
